import base64
import concurrent.futures
import logging
import os
import tempfile
import time

import streamlit as st
from PIL import Image
from langchain.chains import TransformChain
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import UnstructuredPowerPointLoader
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from langchain_core.messages import HumanMessage
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
from langchain_core.prompts import PromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.runnables import RunnablePassthrough
from langchain_core.runnables import chain
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from pptx import Presentation
import aspose.slides as slides
import aspose.pydrawing as drawing

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.DEBUG)

# ìŠ¤ë ˆë“œ í’€ ì‹¤í–‰ì ì´ˆê¸°í™”
executor = concurrent.futures.ThreadPoolExecutor()


# Set verbose if needed
# globals.set_debug(True)


# # # # # # # # # # # #
# í…ŒìŠ¤íŠ¸ ì½”ë“œ. #
# # # # # # # # # # # #


# # # # # # # # # # # # # # # # # # # # # # # #
# ppt íŒŒì¼ ì „ì²´ë¥¼ png ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ëŠ” ì½”ë“œ #
# # # # # # # # # # # # # # # # # # # # # # # #


def pptx_to_png(pptx_filename: str, output_folder='tmp_ppt_images_folder'):
    # ì´ë¯¸ì§€ ì„ì‹œ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    logging.debug('PPT íŒŒì¼ PNGë¡œ ë³€í™˜ ì‹œì‘ :' + pptx_filename)

    png_file_list = []
    with slides.Presentation(pptx_filename) as presentation:
        for slide in presentation.slides:
            # íŒŒì¼ ì €ì¥ ê²½ë¡œ ë° ì´ë¦„.
            tmp_name = os.path.join(output_folder,
                                    "presentation_slide_{0}.png".format(str(slide.slide_number)))
            tmp_name = os.path.abspath(tmp_name)
            logging.debug('ì €ì¥ì‹œì‘ - ' + tmp_name)

            # png íŒŒì¼ ì €ì¥.
            slide.get_thumbnail(1, 1).save(tmp_name, drawing.imaging.ImageFormat.png)
            # png íŒŒì¼ ëª©ë¡ ì €ì¥
            png_file_list.append(tmp_name)
            # time.sleep(0.01)
            logging.debug('ì €ì¥ì™„ë£Œ - ' + tmp_name)

    return png_file_list


# # # # # # # # # # # #
# RAGë¥¼ ìœ„í•œ ì²´ì¸ #
# # # # # # # # # # # #


# ppt í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜(í˜ì´ì§€ë³„)
def get_text_documents_from_pptx(uploaded_pptx_file):
    # print('\n'*10, uploaded_pptx_file.getvalue(), '\n'*5)

    with tempfile.NamedTemporaryFile(delete=False, suffix=".pptx") as tmp_file:
        tmp_file.write(uploaded_pptx_file.getvalue())
        tmp_file_path = tmp_file.name
        tmp_file.close()

        # UnstructuredPowerPointLoaderë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ ë‚´ìš© ì½ê¸°
        loader = UnstructuredPowerPointLoader(
            tmp_file_path, mode='paged', strategy='fast',
        )
    return loader.load(), tmp_file_path  # documentì™€ ì„ì‹œì €ì¥í•œ íŒŒì¼ê²½ë¡œë„ ë¦¬í„´.


# ì´ë¯¸ì§€/í…ìŠ¤íŠ¸ ë„íë¨¼íŠ¸ë¥¼ í•©ì³ì£¼ëŠ” í•¨ìˆ˜
def combine_and_sort_documents(docs_list1: list, docs_list2: list, by='page_number') -> list:
    all_docs = docs_list1 + docs_list2
    all_docs.sort(key=lambda x: x.metadata[by])
    return all_docs


def format_docs(docs):
    # ê²€ìƒ‰í•œ ë¬¸ì„œ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¬¸ë‹¨ìœ¼ë¡œ í•©ì³ì¤ë‹ˆë‹¤.
    return "\n\n".join(doc.page_content for doc in docs)


def get_rag_chain_from_docs(docs_or_vectorstore_for_rag, from_docs=True):
    # text_splitter = RecursiveCharacterTextSplitter(
    #     chunk_size=2000,
    #     chunk_overlap=200
    # )
    # splits = text_splitter.split_documents(docs_for_rag)

    if from_docs:
        # ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±
        vectorstore = FAISS.from_documents(
            documents=docs_or_vectorstore_for_rag, embedding=OpenAIEmbeddings())
    else:
        vectorstore = docs_or_vectorstore_for_rag

    # ê²€ìƒ‰ê¸° ìƒì„±.
    retriever = vectorstore.as_retriever(k=10)

    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
    rag_default_prompt = ("You are an assistant for question-answering tasks. "
                          "Use the following pieces of retrieved context to answer the question. "
                          "If you don't know the answer, just say that 'ì˜ ëª¨ë¥´ê² ì–´ìš”.' "
                          "Use three sentences maximum and keep the answer concise."
                          "\n"
                          "Question: {question} "
                          "\n"
                          "Context: {context} "
                          "\n"
                          "Answer:")

    my_prompt = ChatPromptTemplate(input_variables=['context', 'question'],
                                   messages=[HumanMessagePromptTemplate(
                                       prompt=PromptTemplate(input_variables=['context', 'question'],
                                                             template=rag_default_prompt))])

    llm = ChatOpenAI(model_name="gpt-4o", temperature=0)

    # rag ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    rag_chain = (
            {"context": retriever | format_docs, "question": RunnablePassthrough()}
            | my_prompt
            | llm
            | StrOutputParser()
    )

    return rag_chain, vectorstore


# # # # # # # # # # # #
# ì´ë¯¸ì§€ í•´ì„ ì²´ì¸ #
# # # # # # # # # # # #


# ì´ë¯¸ì§€ ì¶”ì¶œ/ë””ìŠ¤í¬ë¦½ì…˜ í•¨ìˆ˜
def extract_image_description_from_shape(shape, image_output_dir, slide_number, image_count) -> (dict, str):
    extracted_image = shape.image
    image_bytes = extracted_image.blob

    image_format = extracted_image.ext.lower()
    if image_format != 'jpg' and image_format != 'jpeg' and \
            image_format != 'png':
        return None, None

    # ì„ì‹œ ê²½ë¡œì— ì´ë¯¸ì§€ë¥¼ ì €ì¥í•˜ê³  ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜.
    image_filename = os.path.join(image_output_dir, f"slide_{slide_number:03d}_image_{image_count:03d}.{image_format}")
    image_filename = os.path.abspath(image_filename)

    # ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥
    with open(image_filename, "wb") as f:
        f.write(image_bytes)

    # í…ìŠ¤íŠ¸ ë””ìŠ¤í¬ë¦½ì…˜ ìƒì„±
    text_desc_gen_result = get_image_description(image_filename)
    # image_description, node_list, link_list

    # ë§êµ¬ì„±ë„ê°€ ì•„ë‹ ê²½ìš° None ë¦¬í„´
    if text_desc_gen_result is None or \
            text_desc_gen_result['image_description'] is None or text_desc_gen_result['image_description'] == '' or \
            text_desc_gen_result['node_list'] is None or len(text_desc_gen_result['node_list']) == 0 or \
            text_desc_gen_result['link_list'] is None or len(text_desc_gen_result['link_list']) == 0 or \
            text_desc_gen_result['mermaid_code'] is None or text_desc_gen_result['mermaid_code'] == '':
        return None, None

    return text_desc_gen_result, image_filename


# ì´ë¯¸ì§€ì— LLM ë””ìŠ¤í¬ë¦½ì…˜ì„ ë‹¬ì•„ì£¼ëŠ” í•¨ìˆ˜. (shape ì—¬ëŸ¬ê°œë¡œ ìª¼ê°œì§„ ì´ë¯¸ì§€ë“¤ ë•Œë¬¸ì— ë¯¸ì‚¬ìš©)
def get_image_documents_from_pptx_old(pptx_path, image_output_dir='./tmp_extracted_images',
                                      begin_of_image_token='<image>', end_of_image_token='</image>'):
    # í”„ë ˆì  í…Œì´ì…˜ ì—´ê¸°
    prs = Presentation(pptx_path)

    # ì´ë¯¸ì§€ ì„ì‹œ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    if not os.path.exists(image_output_dir):
        os.makedirs(image_output_dir)

    # ë©”íƒ€ë°ì´í„° ìƒì„± - ë””ë ‰í† ë¦¬ì™€ íŒŒì¼ëª…
    directory = os.path.dirname(pptx_path.name)
    filename = os.path.basename(pptx_path.name)

    # ë„íë¨¼íŠ¸ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    docs_list = []
    img_filepath_list = []

    # ìŠ¬ë¼ì´ë“œë§ˆë‹¤ ë°˜ë³µ
    for slide_number, slide in enumerate(prs.slides):
        image_count = 0
        # ìŠ¬ë¼ì´ë“œ ë‚´ì˜ ëª¨ë“  ì‰ì´í”„ í™•ì¸
        for shape in slide.shapes:
            # ì´ë¯¸ì§€ ìš°ì„  ì¶”ì¶œ.
            if hasattr(shape, "image"):
                img_desc_result, img_filename = extract_image_description_from_shape(shape, image_output_dir,
                                                                                     slide_number, image_count)

                if img_desc_result is None:  # jpg, png íŒŒì¼ ê·¸ë¦¼ì´ ì•„ë‹ˆê±°ë‚˜ ë§êµ¬ì„±ë„ê°€ ì•„ë‹ ê²½ìš°.
                    continue

                img_desc_str = ''
                for k, v in img_desc_result.items():
                    img_desc_str += str(k) + ':\n' + str(v) + '\n'
                img_desc_str = img_desc_str.strip()

                # íŠ¹ìˆ˜ í† í° ë¶™ì´ê¸° (ë””ìŠ¤í¬ë¦½ì…˜ ë¶€ë¶„ë§Œ ì‚¬ìš©)
                if begin_of_image_token:
                    img_desc_str = begin_of_image_token + '\n' + img_desc_str
                if end_of_image_token:
                    img_desc_str = img_desc_str + '\n' + end_of_image_token

                # í…ìŠ¤íŠ¸ ìƒì„± ê²°ê³¼ ì €ì¥
                tmp_img_doc = Document(page_content=img_desc_str,
                                       metadata={'source': pptx_path.name,
                                                 'file_directory': directory,
                                                 'filename': filename,
                                                 'page_number': slide_number + 1})

                docs_list.append(tmp_img_doc)
                img_filepath_list.append(img_filename)

    # ì´ë¯¸ì§€ ì¶”ì¶œ ë„íë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸, ì´ë¯¸ì§€ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
    return docs_list, img_filepath_list


# pptx íŒŒì¼ì˜ ì „ì²´ ìŠ¬ë¼ì´ë“œë¥¼ ëª¨ë‘ png íŒŒì¼ë¡œ ì €ì¥í•œ í›„, ë””ìŠ¤í¬ë¦½ì…˜ì„ ë°›ì•„ì˜¤ëŠ” í•¨ìˆ˜.
def get_image_documents_from_pptx(pptx_path: str, image_output_dir='tmp_ppt_images_folder',
                                  begin_of_image_token='<image>', end_of_image_token='</image>'):
    # í”„ë ˆì  í…Œì´ì…˜ ì—´ê¸°
    image_file_list = pptx_to_png(pptx_path, output_folder=image_output_dir)

    # ë©”íƒ€ë°ì´í„° ìƒì„± - ë””ë ‰í† ë¦¬ì™€ íŒŒì¼ëª…
    directory = os.path.dirname(pptx_path)
    filename = os.path.basename(pptx_path)

    # ë„íë¨¼íŠ¸ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    docs_list = []
    img_filepath_list = []

    # ê° íŒŒì¼ë§ˆë‹¤ ë””ìŠ¤í¬ë¦½ì…˜ì„ ê°€ì ¸ì˜¨ë‹¤.
    for slide_number, image_file in enumerate(image_file_list):
        logging.debug('\nìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ ì½ëŠ”ì¤‘ : ' + str(slide_number+1) + ' / ' + str(len(image_file_list)))

        # í…ìŠ¤íŠ¸ ë””ìŠ¤í¬ë¦½ì…˜ ìƒì„±
        desc_gen_result = get_image_description(image_file)
        # image_description, node_list, link_list

        # ë§êµ¬ì„±ë„ê°€ ì•„ë‹ ê²½ìš° skip
        if desc_gen_result is None or \
                desc_gen_result['image_description'] is None or desc_gen_result['image_description'] == '' or \
                desc_gen_result['node_list'] is None or len(desc_gen_result['node_list']) == 0 or \
                desc_gen_result['link_list'] is None or len(desc_gen_result['link_list']) == 0 or \
                desc_gen_result['mermaid_code'] is None or desc_gen_result['mermaid_code'] == '':
            continue

        img_desc_str = ''
        for k, v in desc_gen_result.items():
            img_desc_str += str(k) + ':\n' + str(v) + '\n'
        img_desc_str = img_desc_str.strip()

        # íŠ¹ìˆ˜ í† í° ë¶™ì´ê¸°
        if begin_of_image_token:
            img_desc_str = begin_of_image_token + '\n' + img_desc_str
        if end_of_image_token:
            img_desc_str = img_desc_str + '\n' + end_of_image_token

        # í…ìŠ¤íŠ¸ ìƒì„± ê²°ê³¼ ì €ì¥
        tmp_img_doc = Document(page_content=img_desc_str,
                               metadata={'source': pptx_path,
                                         'file_directory': directory,
                                         'filename': filename,
                                         'page_number': slide_number + 1})

        docs_list.append(tmp_img_doc)
        img_filepath_list.append(image_file)

    # ì´ë¯¸ì§€ ì¶”ì¶œ ë„íë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸, ì´ë¯¸ì§€ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
    return docs_list, img_filepath_list


# # # # # # # # # #
# ì´ë¯¸ì§€ ì²´ì¸ ìƒì„± #
# # # # # # # # # #


# ì´ë¯¸ì§€ íŒŒì¼ì„ ì½ì–´ ì¸ì½”ë”©í•´ì£¼ëŠ” í•¨ìˆ˜
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')


# ë¡œì»¬ ë””ìŠ¤í¬ì˜ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜
def load_image_from_filename(inputs: dict) -> dict:
    """Load image from file and encode it as base64."""
    # íŒŒì¼ëª…ì¼ ê²½ìš°ëŠ” ì½ì–´ì„œ ì¸ì½”ë”© í›„ ë¦¬í„´.
    image_path = inputs["image_path"]
    image_base64 = encode_image(image_path)
    return {"image": image_base64}


def load_image_from_bytes(inputs: dict) -> dict:
    """Load image from file and encode it as base64."""
    # ì´ë¯¸ì§€ bytes íƒ€ì…ì„ utf-8ë¡œ ë””ì½”ë”©
    img_base64 = base64.b64encode(inputs["image_path"]).decode('utf-8')
    return {"image": img_base64}


# ì´ë¯¸ì§€ ì •ë³´ í´ë˜ìŠ¤
class ImageInformation(BaseModel):
    """Information about an image."""
    image_description: str = Field(description="ë§ êµ¬ì„±ì— ëŒ€í•œ ìì„¸í•œ ë””ìŠ¤í¬ë¦½ì…˜(í•œêµ­ì–´)")
    node_list: list[str] = Field(description="ë§êµ¬ì„±ë„ ì†ì˜ ë…¸ë“œ ëª©ë¡")
    link_list: list[str] = Field(description="ë§êµ¬ì„±ë„ ì†ì˜ ë§í¬/ì—ì§€/ì¸í„°í˜ì´ìŠ¤ ëª©ë¡")
    mermaid_code: str = Field(description="Mermaid chart code")


# ì²´ì¸ì„ í•©ì³ì„œ invoke í•´ì£¼ëŠ” í•¨ìˆ˜
def get_image_description(image_path, is_bytes=False) -> dict:
    # ì²´ì¸1-1 - íŒŒì¼ì—ì„œ ê°€ì ¸ì˜¤ê¸°
    load_image_chain = TransformChain(
        input_variables=["image_path"],
        output_variables=["image"],
        transform=load_image_from_filename
    )

    # ì²´ì¸1-2 - ë°”ì´ì¸  ê°ì²´ì—ì„œ ê°€ì ¸ì˜¤ê¸°
    pass_image_chain = TransformChain(
        input_variables=["image_path"],
        output_variables=["image"],
        transform=load_image_from_bytes
    )

    # ì²´ì¸3
    parser = JsonOutputParser(pydantic_object=ImageInformation)

    # ì²´ì¸2
    @chain
    def image_model(inputs: dict) -> str | list[str] | dict:
        """Invoke model with image and prompt."""
        model = ChatOpenAI(temperature=0, model="gpt-4o", max_tokens=4096)  # model="gpt-4-vision-preview"
        msg = model.invoke(
            [HumanMessage(
                content=[
                    {"type": "text", "text": inputs["prompt"]},
                    {"type": "text", "text": parser.get_format_instructions()},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{inputs['image']}"}},
                ])],

        )
        return msg.content

    vision_prompt = """
    Given the image, provide the following information in Korean:
    - ë§êµ¬ì„±ë„ ì´ë¯¸ì§€ì— ëŒ€í•œ ìì„¸í•œ ë””ìŠ¤í¬ë¦½ì…˜ (ì´ë¯¸ì§€ ì† ë…¸ë“œë“¤ê³¼ ë…¸ë“œ ê°„ì˜ ì—°ê²°ì— ëŒ€í•´ ìµœëŒ€í•œ ìƒì„¸í•˜ê²Œ ë¬˜ì‚¬í•  ê²ƒ.)
    - ë§êµ¬ì„±ë„ ì´ë¯¸ì§€ ì† ëª¨ë“  ë…¸ë“œ ì´ë¦„ ëª©ë¡
    - ë§êµ¬ì„±ë„ ì´ë¯¸ì§€ ì† ëª¨ë“  ë§í¬/ì—ì§€/ì¸í„°í˜ì´ìŠ¤ ì´ë¦„ ëª©ë¡
    - ë§êµ¬ì„±ë„ë¥¼ Mermaid codeë¡œ ë³€í™˜í•œ í…ìŠ¤íŠ¸ 
    ë‹¨, ì´ë¯¸ì§€ê°€ ë…¸ë“œì™€ ë§í¬ë¡œ êµ¬ì„±ëœ ë§êµ¬ì„±ë„ ê·¸ë¦¼ì´ ì•„ë‹ ê²½ìš° ëª¨ë‘ ë¹ˆ ë¬¸ìì—´ë¡œë§Œ ì‘ë‹µí•´ì¤˜
    """

    # ì²´ì¸ ìƒì„±
    if is_bytes:
        vision_chain = pass_image_chain | image_model | parser
    else:
        vision_chain = load_image_chain | image_model | parser

    return vision_chain.invoke({'image_path': image_path,
                                'prompt': vision_prompt},
                               )


# # # # # # # # # #
# ì›¹ í˜ì´ì§€ êµ¬ì„±
# # # # # # # # # #


st.set_page_config(layout="wide")
st.title('PPT í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ ë¶„ì„ë´‡')

# message key ë“± ì„¸ì…˜ ì •ë³´ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "api_key" not in st.session_state:  # api key
    st.session_state.api_key = None

# ì´ë¯¸ì§€ íŒŒì¼ ë° ë””ìŠ¤í¬ë¦½ì…˜ë“¤ì— ëŒ€í•œ ìºì‹œ.
if 'img_showed_filenames' not in st.session_state:
    st.session_state.img_showed_filenames = []
if 'imgs' not in st.session_state:
    st.session_state.imgs = []
if 'descriptions' not in st.session_state:
    st.session_state.descriptions = []

# rag -> st.session_state.ppt_rag_chain
if 'ppt_docs' not in st.session_state:  # ëª¨ë“  ë„íë¨¼íŠ¸ ëª©ë¡. íŒŒì¼ì´ ì¶”ê°€ë ë•Œë§ˆë‹¤ ë„íë¨¼íŠ¸ë¥¼ ì¶”ê°€í•˜ê³  ìƒˆ ragë¥¼ ìƒì„±í•œë‹¤.
    st.session_state.ppt_docs = []
    st.session_state.ppt_rag_chain = None
    st.session_state.ppt_vectorstore = None
if 'ppts_already_read_list' not in st.session_state:  # ì´ë¯¸ ì½ì—ˆë˜ ppt íŒŒì¼ ëª©ë¡.
    st.session_state.ppts_already_read_list = []


# ì‚¬ì´ë“œë°” êµ¬ì„±
if os.environ.get("OPENAI_API_KEY"):
    os.environ["OPENAI_API_KEY"] = st.sidebar.text_input('OpenAI API Key',
                                                         value=os.environ["OPENAI_API_KEY"])
else:
    os.environ["OPENAI_API_KEY"] = st.sidebar.text_input('OpenAI API Key',
                                                         placeholder='Input your ChatGPT API key here.')

# rag ê´€ë ¨ parameters
# max_input_len = st.sidebar.number_input('Max input length', min_value=1000, max_value=10000, value=5000, step=100)

user_files = st.sidebar.file_uploader('ì´ë¯¸ì§€ ë˜ëŠ” PPT íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”!', type=['jpg', 'jpeg', 'png', 'ppt', 'pptx'],
                                      accept_multiple_files=True)

# ragìš© vector store ì €ì¥ ë²„íŠ¼
if st.session_state.ppt_vectorstore:
    save_button = st.sidebar.button('ë„íë¨¼íŠ¸ ì €ì¥', type='primary')
    if save_button:
        st.session_state.ppt_vectorstore.save_local('./faiss_db')
        # ë¶ˆëŸ¬ì˜¤ê¸° ì½”ë“œ
        # db_X = FAISS.load_local('./db/test_docs', embeddings=OpenAIEmbeddings(), allow_dangerous_deserialization=True)
else:
    load_button = st.sidebar.button('ë„íë¨¼íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°', type='primary')
    if load_button:
        try:
            st.session_state.ppt_vectorstore = FAISS.load_local('./faiss_db', embeddings=OpenAIEmbeddings(),
                                                                allow_dangerous_deserialization=True)
        except:
            st.toast('DB íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤! (./faiss_db)', icon='ğŸ¤¬')

# ìœ ì €ê°€ ì—…ë¡œë“œí•œ íŒŒì¼ ì²˜ë¦¬.
if user_files:
    for uploaded_file in user_files:
        # st.write("filename:", uploaded_file.name)
        logging.debug(str(uploaded_file))

        bytes_data = uploaded_file.read()

        # ê¸°ì¡´ì— ì¶œë ¥í–ˆë˜ ì´ë¯¸ì§€ì¼ ê²½ìš°.
        if uploaded_file.name in st.session_state.img_showed_filenames:
            ind = st.session_state.img_showed_filenames.index(uploaded_file.name)
            image = st.session_state.imgs[ind]
            desc = st.session_state.descriptions[ind]

            st.image(image, caption=uploaded_file.name, use_column_width=True)
            st.write(desc)

        # ì´ë¯¸ì§€ íŒŒì¼ì¼ ê²½ìš° and ê¸°ì¡´ì— ì´ë¯¸ ì¶œë ¥í•œ íŒŒì¼ì´ ì•„ë‹ ê²½ìš°ì—ë§Œ.
        elif '.jpg' in uploaded_file.name or '.jpeg' in uploaded_file.name or '.png' in uploaded_file.name \
                and uploaded_file.name not in st.session_state.img_showed_filenames:
            image = Image.open(uploaded_file)
            # chat_placeholder.image(image, caption=uploaded_file.name)
            st.image(image, caption=uploaded_file.name, use_column_width=True)

            # logging.debug('image: ')
            # logging.debug(type(image))

            # ë¹„ë™ê¸° ì‘ì—… ì œì¶œ
            future = executor.submit(get_image_description, bytes_data, True)

            # ì‘ì—… ì™„ë£Œ ì—¬ë¶€ í™•ì¸
            with st.spinner("ì´ë¯¸ì§€ ë””ìŠ¤í¬ë¦½ì…˜ ì‘ì„± ì¤‘..."):
                text_gen_result = future.result()  # ì‘ì—… ì™„ë£Œ ì‹œê¹Œì§€ ëŒ€ê¸°
            st.write(text_gen_result)

            # text_gen_result = get_image_description(bytes_data, is_bytes=True)
            # st.write(text_gen_result)

            st.session_state.img_showed_filenames.append(uploaded_file.name)
            st.session_state.imgs.append(image)
            st.session_state.descriptions.append(text_gen_result)

        # ppt íŒŒì¼ì¼ ê²½ìš° and ê¸°ì¡´ì— ì½ì—ˆë˜ ppt íŒŒì¼ì´ ì•„ë‹ ê²½ìš°.
        elif '.ppt' in uploaded_file.name and uploaded_file.name not in st.session_state.ppts_already_read_list:
            # pprint(uploaded_file)
            # ìƒˆë¡œìš´ íŒŒì¼ì„ ì½ì€ íŒŒì¼ ëª©ë¡ì— ë„£ëŠ”ë‹¤. (ì„¸ì…˜ ìœ ì§€ ì¤‘ íŒŒì¼ ë‹¤ì‹œ ì½ëŠ”ê²ƒ ë°©ì§€)
            st.session_state.ppts_already_read_list.append(uploaded_file.name)

            # ppt ë‚´ í…ìŠ¤íŠ¸ doc ìƒì„±
            with st.spinner('íŒŒì›Œí¬ì¸íŠ¸ íŒŒì¼ ë‚´ í…ìŠ¤íŠ¸ ì½ëŠ” ì¤‘...'):
                docs1, tmp_pptxfile_path = get_text_documents_from_pptx(uploaded_file)

            st.write(docs1[:5])  # í…ìŠ¤íŠ¸ doc (ì¼ë¶€ë§Œ) í™”ë©´ ì¶œë ¥

            with st.spinner('íŒŒì›Œí¬ì¸íŠ¸ íŒŒì¼ ë‚´ ì´ë¯¸ì§€ ì½ëŠ” ì¤‘...'):
                # ppt ë‚´ ì´ë¯¸ì§€ë¥¼ ëª¨ë‘ ë½‘ì•„ doc ìƒì„±
                docs2, img_file_list = get_image_documents_from_pptx(tmp_pptxfile_path)

            # ì´ë¯¸ì§€ & ì´ë¯¸ì§€ doc í™”ë©´ ì¶œë ¥
            for img_file, img_doc in zip(img_file_list, docs2):
                image = Image.open(img_file)
                # chat_placeholder.image(image, caption=uploaded_file.name)
                st.image(image, caption=img_file, use_column_width=True)
                st.write(img_doc)

            with st.spinner('RAG Chain êµ¬ì„±ì¤‘...'):
                # ëª¨ë“  ë„íë¨¼íŠ¸ë¥¼ í•©ì¹œë‹¤
                st.session_state.ppt_docs += combine_and_sort_documents(docs1, docs2)
                logging.debug('ì „ì²´ docs ê¸¸ì´: ' + str(len(st.session_state.ppt_docs)))

                # ragë¥¼ ë§Œë“ ë‹¤.
                st.session_state.ppt_rag_chain, \
                    st.session_state.ppt_vectorstore = get_rag_chain_from_docs(st.session_state.ppt_docs)
                st.write('íŒŒì›Œí¬ì¸íŠ¸ ë‚´ìš© ì´í•´ ì™„ë£Œ! ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?')


# ë©”ì¸ í˜ì´ì§€ êµ¬ì„±
chat_placeholder = st.empty()

# ì±„íŒ… ëª©ë¡ì„ ì¶œë ¥í•´ì¤„ ì»¨í…Œì´ë„ˆ ìƒì„±
text_container = st.container(border=True)
# text_container.title('AIì™€ì˜ ì˜¤ë¶“í•œ ì±„íŒ…ë°©')

for message in st.session_state.messages:
    with text_container:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

user_chat = st.chat_input("Say something")

if user_chat:
    st.session_state.messages.append({"role": "user", "content": user_chat})  # history ì¶”ê°€
    with text_container:
        with st.chat_message('user'):
            st.markdown(user_chat)

    # AI response
    if st.session_state.ppt_rag_chain:
        with text_container:
            with st.spinner('ë‹µë³€ ìƒì„±ì¤‘...'):
                answer = st.session_state.ppt_rag_chain.invoke(user_chat)

        st.session_state.messages.append({"role": "assistant", "content": answer})
        with text_container:
            with st.chat_message('assistant'):
                st.markdown(answer)
